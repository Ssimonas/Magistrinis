myData[myData$KODAS_STATUSAI == 5,]
######################## Find bankcrupt rows ########################
head(myData)
subset(myData, KODAS_STATUSAI == 5)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
which(duplicated(Bankrupt2018Monthly$ekch))
ind_rm <- which(duplicated(Bankrupt2018Monthly$ekch))
Bankrupt2018MonthlyNoDup <- Bankrupt2018Monthly[-ind_rm,]
write.csv(Bankrupt2018Monthly, file="2018_bankrupt_no_dups.csv", row.names = FALSE)
View(Bankrupt2018MonthlyNoDup)
write.csv(Bankrupt2018MonthlyNoDup, file="2018_bankrupt_no_dups.csv", row.names = FALSE)
head(Bankrupt2018Monthly)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
ind_rm <- which(duplicated(Bankrupt2018Monthly$ekch))
ind_rm
######################## Find bankcrupt rows ########################
head(myData)
######################## Find bankcrupt rows ########################
head(myData[3,])
head(Bankrupt2018Monthly)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
head(Bankrupt2018Monthly)
View(Bankrupt2018Monthly)
Bankrupt2018MonthlyNoDup <- subset(Bankrupt2018Monthly, duplicated(ekch))
head(Bankrupt2018MonthlyNoDup)
Bankrupt2018MonthlyNoDup <- duplicated(Bankrupt2018Monthly$ekch)
head(Bankrupt2018MonthlyNoDup)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
head(Bankrupt2018MonthlyNoDup)
head(Bankrupt2018Monthly)
head(row(Bankrupt2018Monthly))
head(rownames(Bankrupt2018Monthly))
head(Bankrupt2018Monthly)
Bankrupt2018MonthlyNoDup <- duplicated(Bankrupt2018Monthly$ekch)
head(Bankrupt2018MonthlyNoDup)
Bankrupt2018MonthlyNoDup <- which(duplicated(Bankrupt2018Monthly$ekch))
Bankrupt2018MonthlyNoDup
Bankrupt2018MonthlyNoDup <- Bankrupt2018Monthly[-ind_rm,]
head(Bankrupt2018MonthlyNoDup)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
Bankrupt2018MonthlyNoDup <- Bankrupt2018Monthly[-ind_rm,]
write.csv(Bankrupt2018MonthlyNoDup, file="2018_bankrupt_no_dups.csv", row.names = FALSE)
ind_rm <- rownames(Bankrupt2018MonthlyNoDup)
ind_rm
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyNoDup))
ind_rm
myData <- myData[-ind_rm,]
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
write.csv(smallData, file="smallData200k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
Bankrupt2018MonthlyNoDup <- Bankrupt2018Monthly[-ind_rm,]
# Everything left are duplicates
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyNoDup))
smallData <- smallData[-ind_rm,]
write.csv(smallData, file="smallData200k_nodups.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
ind_rm
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
head(smallData)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
Bankrupt2018Monthly
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
ind_rm
Bankrupt2018MonthlyNoDup <- Bankrupt2018Monthly[-ind_rm,]
Bankrupt2018MonthlyNoDup
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
nrow(ind_rm)
length(ind_rm)
# Removing unique values or first of duplicates
ind_rm <- which(duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:400000,]
write.csv(smallData, file="smallData_400k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:600000,]
write.csv(smallData, file="smallData_600k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
# Removing unique values or first of duplicates
ind_rm <- which(duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
duplicated(Bankrupt2018Monthly$ekch)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:1000000,]
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
head(smallData)
head(myData)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
myData <- myDataRaw
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:400000,]
write.csv(smallData, file="smallData_400k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
write.csv(smallData, file="smallData_200k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
Bankrupt2018MonthlyOnlyDups <- Bankrupt2018Monthly[-ind_rm,]
# Everything left are duplicates
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyNoDup))
# Everything left are duplicates
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyNoDup))
smallData <- smallData[-ind_rm,]
write.csv(smallData, file="smallData200k_nodups.csv", row.names = FALSE)
# Everything left are duplicates
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyNoDup))
ind_rm
length(ind_rm)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
Bankrupt2018MonthlyOnlyDups <- Bankrupt2018Monthly[-ind_rm,]
# Everything left are duplicates
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyOnlyDups))
ind_rm
smallData <- smallData[-ind_rm,]
write.csv(smallData, file="smallData200k_nodups.csv", row.names = FALSE)
write.csv(smallData, file="smallData_200k.csv", row.names = FALSE)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
write.csv(smallData, file="smallData_200k.csv", row.names = FALSE)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
TIME <- Sys.time()
myData <- read.csv('data\\doodle\\im2018.csv',header=T, stringsAsFactors = FALSE, sep=',')
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
write.csv(smallData, file="smallData_200k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
Bankrupt2018MonthlyOnlyDups <- Bankrupt2018Monthly[-ind_rm,]
# Everything left are duplicates with original row indexes
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyOnlyDups))
smallData <- smallData[-ind_rm,]
write.csv(smallData, file="smallData200k_nodups.csv", row.names = FALSE)
########## Variable correleation? - to see which columns are 1:1 () ###########
cor(smallData, y=NULL,use="everything", method=c("pearson", "kendall", "spearman"))
########## Variable correleation? - to see which columns are 1:1 () ###########
correlation(smallData, y=NULL,use="everything", method=c("pearson", "kendall", "spearman"))
########## Variable correleation? - to see which columns are 1:1 () ###########
cor(smallData, y=NULL,use="everything", method=c("pearson", "kendall", "spearman"))
########## Variable correleation? - to see which columns are 1:1 () ###########
str(smallData)
smallData$pirkimai_pvm_dekl
smallData$pirkimai_pvm_dekl[12000:13000,]
smallData$pirkimai_pvm_dekl[12000:13000]
install.packages(@polycor)
install.packages("polycor")
library("polycor")
hetcor(smallData)
######################## FIX VARIABLES #######################
# Delete ones with all NA values
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
smallData$pardavimai_pvm_dekl <- as.numeric(smallData$pardavimai_pvm_dekl)
head(smallData)
str(smallData)
summary(smallData$pardavimai_pvm_dekl)
summary(myData$pardavimai_pvm_dekl)
myData <- read.csv('data\\doodle\\im2018_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
head(myData)
summary(myData)
######################## FIX VARIABLES #######################
# Delete ones with all NA values
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
myData$pardavimai_pvm_dekl <- as.numeric(myData$pardavimai_pvm_dekl)
summary(myData)
myData <- read.csv('data\\doodle\\im2018_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
myDataRaw <- myData
######################## FIX VARIABLES #######################
# Delete ones with all NA values
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
myData$pardavimai_pvm_dekl <- as.numeric(gsub(",","",myData$pardavimai_pvm_dekl))
summary(myData$pardavimai_pvm_dekl)
str(myData)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
write.csv(smallData, file="smallData_200k.csv", row.names = FALSE)
######################## Find duplicate bankcrupt rows ########################
smallData <- myDataRaw[1:200000,]
write.csv(smallData, file="smallData_200k_raw.csv", row.names = FALSE)
summary(myData)
######################## FIX VARIABLES #######################
# Delete ones with all NA values
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
myData$pardavimai_pvm_dekl <- as.numeric(gsub(",","",myData$pardavimai_pvm_dekl))
myData$pvm_dekl_36 <- as.numeric(gsub(",","",myData$pvm_dekl_36))
myData$pirkimai_pvm_dekl <- as.numeric(gsub(",","",myData$pirkimai_pvm_dekl))
myData$laik_tipas_pvm <- as.numeric(gsub(",","",myData$laik_tipas_pvm))
summary(myData)
#setwd('C:\\Users\\Simonas\\Desktop\\Magistrinis\\Magistras GIT')
# Set working directory to script directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
TIME <- Sys.time()
myData <- read.csv('data\\doodle\\im2017_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
summary(myData)
head(myData)
#setwd('C:\\Users\\Simonas\\Desktop\\Magistrinis\\Magistras GIT')
# Set working directory to script directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
TIME <- Sys.time()
myData <- read.csv('data\\doodle\\im2019_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
summary(myData)
head(myData)
######################## FIX VARIABLES #######################
# Delete ones with all NA values
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
myData$pardavimai_pvm_dekl <- as.numeric(gsub(",","",myData$pardavimai_pvm_dekl))
myData$pvm_dekl_36 <- as.numeric(gsub(",","",myData$pvm_dekl_36))
myData$pirkimai_pvm_dekl <- as.numeric(gsub(",","",myData$pirkimai_pvm_dekl))
myData$laik_tipas_pvm <- as.numeric(gsub(",","",myData$laik_tipas_pvm))
summary(myData$pardavimai_pvm_dekl)
summary(myData[,1:10])
summary(myData$pvm_dekl_36)
summary(myData$pirkimai_pvm_dekl)
summary(myData$laik_tipas_pvm)
columns2019 <- colnames(myData)
columns2019
myData <- read.csv('data\\doodle\\im2018_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
#columns2019 <- colnames(myData)
columns2018 <- colnames(myData)
myData <- read.csv('data\\doodle\\im2017_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
#columns2019 <- colnames(myData)
#columns2018 <- colnames(myData)
columns2017 <- colnames(myData)
myData <- read.csv('data\\doodle\\im2016_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
#columns2019 <- colnames(myData)
#columns2018 <- colnames(myData)
#columns2017 <- colnames(myData)
columns2016 <- colnames(myData)
myData <- read.csv('data\\doodle\\im2015_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
#columns2019 <- colnames(myData)
#columns2018 <- colnames(myData)
#columns2017 <- colnames(myData)
#columns2016 <- colnames(myData)
columns2015 <- colnames(myData)
myData <- read.csv('data\\doodle\\im2014_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
View(smallData)
View(smallData)
#columns2019 <- colnames(myData)
#columns2018 <- colnames(myData)
#columns2017 <- colnames(myData)
#columns2016 <- colnames(myData)
#columns2015 <- colnames(myData)
columns2014 <- colnames(myData)
myData <- read.csv('data\\doodle\\im2013_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
#columns2019 <- colnames(myData)
#columns2018 <- colnames(myData)
#columns2017 <- colnames(myData)
#columns2016 <- colnames(myData)
#columns2015 <- colnames(myData)
#columns2014 <- colnames(myData)
columns2013 <- colnames(myData)
setdiff(columns2019,columns2018)
setdiff(columns2019,columns2013)
setdiff(columns2013,columns2019)
setdiff(columns2019,columns2018)
setdiff(columns2018,columns2019)
setdiff(columns2018,columns2017)
setdiff(columns2017,columns2018)
setdiff(columns2016,columns2018)
setdiff(columns2018,columns2016)
setdiff(columns2018,columns2015)
setdiff(columns2015,columns2018)
setdiff(columns2014,columns2018)
setdiff(columns2018,columns2014)
setdiff(columns2013,columns2014)
setdiff(columns2018,columns2017)
setdiff(columns2017,columns2018)
setdiff(columns2018,columns2016)
setdiff(columns2016,columns2018)
setdiff(columns2018,columns2015)
setdiff(columns2015,columns2018)
setdiff(columns2018,columns2014)
setdiff(columns2014,columns2018)
setdiff(columns2018,columns2013)
setdiff(columns2013,columns2018)
######################## FIX VARIABLES #######################
# Delete ones with all NA values
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
myData$pardavimai_pvm_dekl <- as.numeric(gsub(",","",myData$pardavimai_pvm_dekl))
myData$pvm_dekl_36 <- as.numeric(gsub(",","",myData$pvm_dekl_36))
myData$pirkimai_pvm_dekl <- as.numeric(gsub(",","",myData$pirkimai_pvm_dekl))
myData$laik_tipas_pvm <- as.numeric(gsub(",","",myData$laik_tipas_pvm))
summary(myData)
myData <- read.csv('data\\doodle\\im2019_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
######################## FIX VARIABLES #######################
# Delete ones with all NA values
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
myData$pardavimai_pvm_dekl <- as.numeric(gsub(",","",myData$pardavimai_pvm_dekl))
myData$pvm_dekl_36 <- as.numeric(gsub(",","",myData$pvm_dekl_36))
myData$pirkimai_pvm_dekl <- as.numeric(gsub(",","",myData$pirkimai_pvm_dekl))
myData$laik_tipas_pvm <- as.numeric(gsub(",","",myData$laik_tipas_pvm))
summary(myData)
str(myData)
myData <- read.csv('data\\doodle\\im2019_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
summ <- summary(myData)
summ
sum(is.na(myData$laik_tipas_pvm))
sum((myData$laik_tipas_pvm == ""))
sum((myData$laik_tipas_pvm == "P"))
sum((myData$laik_tipas_pvm == "M"))
myData <- select(myData, -c(KLN_KLNT_TYPE, NAUJAS_PVM_MOK, FIN_ATASKAITA, gpm, pvm, pm, akc, kiti, VKR_SEKCIJA, APRASYMAS_FORMA))
######################## 3. REMOVE EMPTY OR UNIMPORTANT VARIABLES #######################
# NAUJAS_PVM_MOK (?)
# KLN_KLNT_TYPE
# FIN_ATASKAITA
# gpm, pvm, pm, akc, kiti - empty values
# B_SANAUDOS - no data in 2019, 2018 datasets (???)
# VKR_SEKCIJA, EV1_ID_NAME_TR - similiar variables (EV1_ID_NAME_TR - more detailed VKR_SEKCIJA)
# APRASYMAS_FORMA == KODAS_FORMA (drop APRASYMAS_FORMA)
library(dplyr)
myData <- select(myData, -c(KLN_KLNT_TYPE, NAUJAS_PVM_MOK, FIN_ATASKAITA, gpm, pvm, pm, akc, kiti, VKR_SEKCIJA, APRASYMAS_FORMA))
myData2018Year <- select(filter(myData, str_detect(myData$DATE, "DEC")),everything())
#myData %>% filter(str_detect(DATE, "DEC"))
library(stringr)
library(dplyr)
myData2018Year <- select(filter(myData, str_detect(myData$DATE, "DEC")),everything())
myData2018Year <- select(filter(myData, -str_detect(myData$DATE, "DEC")),everything())
myData2018Year <- select(filter(myData, str_detect(myData$DATE, "DEC")),everything())
myDataYear <- select(filter(myData, str_detect(myData$DATE, "DEC")),everything())
myDataMonth <- select(filter(myData, str_detect(myData$DATE, "DEC",negate = TRUE)),everything())
summary(myDataMonth)
summary(myDataYear)
write.csv(myDataYear, file="im2019_met.csv", row.names = FALSE)
summary(myDataYear)
summary(myDataMonth)
sapply(myData, function(x) sum(is.na(x)))
sapply(myData, function(x){sum(is.na(x))})
sapply(myData, function(x){
if(sum(is.na(x))==nrow(x)){
return(colname)
}
})
nrow(myData)
sapply(myData, function(x){
if(sum(is.na(x))==nrow(x)){
return(99)
}
})
sapply(myData, function(x){sum(is.na(x))})
empty_values <- sapply(myData, function(x){sum(is.na(x))})
str(empty_values)
empty_values[empty_values == nrow(myData)]
empty_values <- sapply(myDataMonth, function(x){sum(is.na(x))})
empty_values[empty_values == nrow(myDataMonth)]
empty_values <- sapply(myDataYear, function(x){sum(is.na(x))})
empty_values[empty_values == nrow(myDataYear)]
sum(empty_values[empty_values == nrow(myDataMonth)])
length(empty_values[empty_values == nrow(myDataMonth)])
nrow(empty_values[empty_values == nrow(myDataMonth)])
count(empty_values[empty_values == nrow(myDataMonth)])
count(empty_values[empty_values == nrow(myDataMonth)])
length(empty_values)
length(empty_values[empty_values == nrow(myDataMonth)])
empty_values[empty_values == nrow(myDataMonth)]
empty_values[empty_values == nrow(myDataYear)]
empty_vars <- empty_values[empty_values == nrow(myDataMonth)]
length(empty_vars)
empty_values <- sapply(myDataMonth, function(x){sum(is.na(x))})
empty_vars <- empty_values[empty_values == nrow(myDataMonth)]
length(empty_vars)
empty_values_month[empty_values_month == nrow(myDataMonth)]
empty_values_month <- sapply(myDataMonth, function(x){sum(is.na(x))})
empty_values_month[empty_values_month == nrow(myDataMonth)]
length(empty_values_month[empty_values_month == nrow(myDataMonth)])
length(empty_values[empty_values == nrow(myDataYear)])
empty_values <- sapply(myDataYear, function(x){sum(is.na(x))})
empty_values[empty_values == nrow(myDataYear)]
length(empty_values[empty_values == nrow(myDataYear)])
myData <- read.csv('data\\doodle\\im2017_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
#!!!!!!!!!!
# pardavimai_pvm_dekl        : chr  " " " " " " " " ...
# pvm_dekl_36                : chr  " " " " " " " " ...
# pirkimai_pvm_dekl          : chr  " " " " " " " " ...
######################## 2. FIX VARIABLES #######################
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
myData$pardavimai_pvm_dekl <- as.numeric(gsub(",","",myData$pardavimai_pvm_dekl))
myData$pvm_dekl_36 <- as.numeric(gsub(",","",myData$pvm_dekl_36))
myData$pirkimai_pvm_dekl <- as.numeric(gsub(",","",myData$pirkimai_pvm_dekl))
myData <- select(myData, -c(KLN_KLNT_TYPE, NAUJAS_PVM_MOK, FIN_ATASKAITA, gpm, pvm, pm, akc, kiti, VKR_SEKCIJA, APRASYMAS_FORMA))
myDataYear <- select(filter(myData, str_detect(myData$DATE, "DEC")),everything())
myDataMonth <- select(filter(myData, str_detect(myData$DATE, "DEC",negate = TRUE)),everything())
empty_values_month <- sapply(myDataMonth, function(x){sum(is.na(x))})
empty_values_month[empty_values_month == nrow(myDataMonth)]
length(empty_values_month[empty_values_month == nrow(myDataMonth)])
empty_values <- sapply(myDataYear, function(x){sum(is.na(x))})
empty_values[empty_values == nrow(myDataYear)]
length(empty_values[empty_values == nrow(myDataYear)])
myData <- read.csv('data\\doodle\\im2016_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
#!!!!!!!!!!
# pardavimai_pvm_dekl        : chr  " " " " " " " " ...
# pvm_dekl_36                : chr  " " " " " " " " ...
# pirkimai_pvm_dekl          : chr  " " " " " " " " ...
######################## 2. FIX VARIABLES #######################
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
myData$pardavimai_pvm_dekl <- as.numeric(gsub(",","",myData$pardavimai_pvm_dekl))
myData$pvm_dekl_36 <- as.numeric(gsub(",","",myData$pvm_dekl_36))
myData$pirkimai_pvm_dekl <- as.numeric(gsub(",","",myData$pirkimai_pvm_dekl))
myData <- select(myData, -c(KLN_KLNT_TYPE, NAUJAS_PVM_MOK, FIN_ATASKAITA, gpm, pvm, pm, akc, kiti, VKR_SEKCIJA, APRASYMAS_FORMA))
myDataYear <- select(filter(myData, str_detect(myData$DATE, "DEC")),everything())
myDataMonth <- select(filter(myData, str_detect(myData$DATE, "DEC",negate = TRUE)),everything())
empty_values_month <- sapply(myDataMonth, function(x){sum(is.na(x))})
empty_values_month[empty_values_month == nrow(myDataMonth)]
length(empty_values_month[empty_values_month == nrow(myDataMonth)])
empty_values <- sapply(myDataYear, function(x){sum(is.na(x))})
empty_values[empty_values == nrow(myDataYear)]
length(empty_values[empty_values == nrow(myDataYear)])
myData <- read.csv('data\\doodle\\im2015_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
#!!!!!!!!!!
# pardavimai_pvm_dekl        : chr  " " " " " " " " ...
# pvm_dekl_36                : chr  " " " " " " " " ...
# pirkimai_pvm_dekl          : chr  " " " " " " " " ...
######################## 2. FIX VARIABLES #######################
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
myData$pardavimai_pvm_dekl <- as.numeric(gsub(",","",myData$pardavimai_pvm_dekl))
myData$pvm_dekl_36 <- as.numeric(gsub(",","",myData$pvm_dekl_36))
myData$pirkimai_pvm_dekl <- as.numeric(gsub(",","",myData$pirkimai_pvm_dekl))
myData <- select(myData, -c(KLN_KLNT_TYPE, NAUJAS_PVM_MOK, FIN_ATASKAITA, gpm, pvm, pm, akc, kiti, VKR_SEKCIJA, APRASYMAS_FORMA))
myDataYear <- select(filter(myData, str_detect(myData$DATE, "DEC")),everything())
myDataMonth <- select(filter(myData, str_detect(myData$DATE, "DEC",negate = TRUE)),everything())
empty_values_month <- sapply(myDataMonth, function(x){sum(is.na(x))})
empty_values_month[empty_values_month == nrow(myDataMonth)]
length(empty_values_month[empty_values_month == nrow(myDataMonth)])
empty_values <- sapply(myDataYear, function(x){sum(is.na(x))})
empty_values[empty_values == nrow(myDataYear)]
length(empty_values[empty_values == nrow(myDataYear)])
myData <- read.csv('data\\doodle\\im2014_utf8.csv',header=T, stringsAsFactors = FALSE, sep=',')
#!!!!!!!!!!
# pardavimai_pvm_dekl        : chr  " " " " " " " " ...
# pvm_dekl_36                : chr  " " " " " " " " ...
# pirkimai_pvm_dekl          : chr  " " " " " " " " ...
######################## 2. FIX VARIABLES #######################
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
myData$pardavimai_pvm_dekl <- as.numeric(gsub(",","",myData$pardavimai_pvm_dekl))
myData$pvm_dekl_36 <- as.numeric(gsub(",","",myData$pvm_dekl_36))
myData$pirkimai_pvm_dekl <- as.numeric(gsub(",","",myData$pirkimai_pvm_dekl))
myData <- select(myData, -c(KLN_KLNT_TYPE, NAUJAS_PVM_MOK, FIN_ATASKAITA, gpm, pvm, pm, akc, kiti, VKR_SEKCIJA, APRASYMAS_FORMA))
myDataYear <- select(filter(myData, str_detect(myData$DATE, "DEC")),everything())
myDataMonth <- select(filter(myData, str_detect(myData$DATE, "DEC",negate = TRUE)),everything())
empty_values_month <- sapply(myDataMonth, function(x){sum(is.na(x))})
empty_values_month[empty_values_month == nrow(myDataMonth)]
length(empty_values_month[empty_values_month == nrow(myDataMonth)])
empty_values <- sapply(myDataYear, function(x){sum(is.na(x))})
empty_values[empty_values == nrow(myDataYear)]
length(empty_values[empty_values == nrow(myDataYear)])
