setwd('C:\\Users\\silaks\\Desktop\\Simo\\Magistrinis\\R\\') # this line doesn't work on MAC OS
# converts all factors to numeric type, if levels>3 dummyVars could be considered
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
TIME <- Sys.time()
myData <- read.csv('data\\doodle\\im2018.csv',header=T, stringsAsFactors = FALSE, sep=',')
print(Sys.time() - TIME)
#myData %>% filter(str_detect(DATE, "DEC"))
library(stringr)
library(dplyr)
myData2018Year <- select(filter(myData, str_detect(myData$DATE, "DEC")),everything())
str(myData2018Year)
summary(myData$B_NUOSAVAS_KAPITALAS)
summary(myData$likutis)
summary(myData)
summary(myData2018Year)
myData$DATE <- toString(myData$DATE)
#str(myData)
#head(myData$APRASYMAS_FORMA,20)
#head(myData$ekch,20)
#myData$APRASYMAS_FORMA[1]
#myData$KODAS_STATUSAI[1]
str(myData)
setwd('C:\\Users\\Simonas\\Desktop\\Magistrinis\\Magistras GIT') # this line doesn't work on MAC OS
# converts all factors to numeric type, if levels>3 dummyVars could be considered
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
TIME <- Sys.time()
myData <- read.csv('data\\doodle\\im2018.csv',header=T, stringsAsFactors = FALSE, sep=',')
#str(myData)
#head(myData$APRASYMAS_FORMA,20)
#head(myData$ekch,20)
#myData$APRASYMAS_FORMA[1]
#myData$KODAS_STATUSAI[1]
str(myData)
myData$DATE <- toString(myData$DATE)
#str(myData)
#head(myData$APRASYMAS_FORMA,20)
#head(myData$ekch,20)
#myData$APRASYMAS_FORMA[1]
#myData$KODAS_STATUSAI[1]
str(myData)
myData <- read.csv('data\\doodle\\im2018.csv',header=T, stringsAsFactors = FALSE, sep=',')
myDataRaw <- myData
#str(myData)
#head(myData$APRASYMAS_FORMA,20)
#head(myData$ekch,20)
#myData$APRASYMAS_FORMA[1]
#myData$KODAS_STATUSAI[1]
str(myData)
#myData %>% filter(str_detect(DATE, "DEC"))
library(stringr)
library(dplyr)
myData2018Year <- select(filter(myData, str_detect(myData$DATE, "DEC")),everything())
myData2018Year <- select(filter(myData, str_detect(myData$DATE, "DEC")),everything())
str(myData2018Year)
write.csv(myData2018Year, file="Year2018_R.csv", row.names = FALSE)
summary(myData2018Year)
Bankrupt2018Monthly <- myData[myData$KODAS_STATUSAI = 5,]
Bankrupt2018Monthly <- myData[myData$KODAS_STATUSAI == 5,]
write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
myData[myData$KODAS_STATUSAI == 5,]
######################## Find bankcrupt rows ########################
head(myData)
subset(myData, KODAS_STATUSAI == 5)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
which(duplicated(Bankrupt2018Monthly$ekch))
ind_rm <- which(duplicated(Bankrupt2018Monthly$ekch))
Bankrupt2018MonthlyNoDup <- Bankrupt2018Monthly[-ind_rm,]
write.csv(Bankrupt2018Monthly, file="2018_bankrupt_no_dups.csv", row.names = FALSE)
View(Bankrupt2018MonthlyNoDup)
write.csv(Bankrupt2018MonthlyNoDup, file="2018_bankrupt_no_dups.csv", row.names = FALSE)
head(Bankrupt2018Monthly)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
ind_rm <- which(duplicated(Bankrupt2018Monthly$ekch))
ind_rm
######################## Find bankcrupt rows ########################
head(myData)
######################## Find bankcrupt rows ########################
head(myData[3,])
head(Bankrupt2018Monthly)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
head(Bankrupt2018Monthly)
View(Bankrupt2018Monthly)
Bankrupt2018MonthlyNoDup <- subset(Bankrupt2018Monthly, duplicated(ekch))
head(Bankrupt2018MonthlyNoDup)
Bankrupt2018MonthlyNoDup <- duplicated(Bankrupt2018Monthly$ekch)
head(Bankrupt2018MonthlyNoDup)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
head(Bankrupt2018MonthlyNoDup)
head(Bankrupt2018Monthly)
head(row(Bankrupt2018Monthly))
head(rownames(Bankrupt2018Monthly))
head(Bankrupt2018Monthly)
Bankrupt2018MonthlyNoDup <- duplicated(Bankrupt2018Monthly$ekch)
head(Bankrupt2018MonthlyNoDup)
Bankrupt2018MonthlyNoDup <- which(duplicated(Bankrupt2018Monthly$ekch))
Bankrupt2018MonthlyNoDup
Bankrupt2018MonthlyNoDup <- Bankrupt2018Monthly[-ind_rm,]
head(Bankrupt2018MonthlyNoDup)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
Bankrupt2018MonthlyNoDup <- Bankrupt2018Monthly[-ind_rm,]
write.csv(Bankrupt2018MonthlyNoDup, file="2018_bankrupt_no_dups.csv", row.names = FALSE)
ind_rm <- rownames(Bankrupt2018MonthlyNoDup)
ind_rm
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyNoDup))
ind_rm
myData <- myData[-ind_rm,]
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
write.csv(smallData, file="smallData200k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
Bankrupt2018MonthlyNoDup <- Bankrupt2018Monthly[-ind_rm,]
# Everything left are duplicates
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyNoDup))
smallData <- smallData[-ind_rm,]
write.csv(smallData, file="smallData200k_nodups.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
ind_rm
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
head(smallData)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
Bankrupt2018Monthly
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
ind_rm
Bankrupt2018MonthlyNoDup <- Bankrupt2018Monthly[-ind_rm,]
Bankrupt2018MonthlyNoDup
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
nrow(ind_rm)
length(ind_rm)
# Removing unique values or first of duplicates
ind_rm <- which(duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:400000,]
write.csv(smallData, file="smallData_400k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:600000,]
write.csv(smallData, file="smallData_600k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
# Removing unique values or first of duplicates
ind_rm <- which(duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
duplicated(Bankrupt2018Monthly$ekch)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:1000000,]
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
head(smallData)
head(myData)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
myData <- myDataRaw
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:400000,]
write.csv(smallData, file="smallData_400k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(myData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
write.csv(smallData, file="smallData_200k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
Bankrupt2018MonthlyOnlyDups <- Bankrupt2018Monthly[-ind_rm,]
# Everything left are duplicates
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyNoDup))
# Everything left are duplicates
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyNoDup))
smallData <- smallData[-ind_rm,]
write.csv(smallData, file="smallData200k_nodups.csv", row.names = FALSE)
# Everything left are duplicates
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyNoDup))
ind_rm
length(ind_rm)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
Bankrupt2018MonthlyOnlyDups <- Bankrupt2018Monthly[-ind_rm,]
# Everything left are duplicates
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyOnlyDups))
ind_rm
smallData <- smallData[-ind_rm,]
write.csv(smallData, file="smallData200k_nodups.csv", row.names = FALSE)
write.csv(smallData, file="smallData_200k.csv", row.names = FALSE)
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
write.csv(smallData, file="smallData_200k.csv", row.names = FALSE)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
TIME <- Sys.time()
myData <- read.csv('data\\doodle\\im2018.csv',header=T, stringsAsFactors = FALSE, sep=',')
######################## Find duplicate bankcrupt rows ########################
smallData <- myData[1:200000,]
write.csv(smallData, file="smallData_200k.csv", row.names = FALSE)
# All bankrupt rows (rownames as original dataset row indexes)
Bankrupt2018Monthly <- subset(smallData, KODAS_STATUSAI == 5)
#write.csv(Bankrupt2018Monthly, file="2018_bankrupt.csv", row.names = FALSE)
nrow(Bankrupt2018Monthly)
# Removing unique values or first of duplicates
ind_rm <- which(!duplicated(Bankrupt2018Monthly$ekch))
length(ind_rm)
Bankrupt2018MonthlyOnlyDups <- Bankrupt2018Monthly[-ind_rm,]
# Everything left are duplicates with original row indexes
ind_rm <- as.integer(rownames(Bankrupt2018MonthlyOnlyDups))
smallData <- smallData[-ind_rm,]
write.csv(smallData, file="smallData200k_nodups.csv", row.names = FALSE)
########## Variable correleation? - to see which columns are 1:1 () ###########
cor(smallData, y=NULL,use="everything", method=c("pearson", "kendall", "spearman"))
########## Variable correleation? - to see which columns are 1:1 () ###########
correlation(smallData, y=NULL,use="everything", method=c("pearson", "kendall", "spearman"))
########## Variable correleation? - to see which columns are 1:1 () ###########
cor(smallData, y=NULL,use="everything", method=c("pearson", "kendall", "spearman"))
########## Variable correleation? - to see which columns are 1:1 () ###########
str(smallData)
smallData$pirkimai_pvm_dekl
smallData$pirkimai_pvm_dekl[12000:13000,]
smallData$pirkimai_pvm_dekl[12000:13000]
install.packages(@polycor)
install.packages("polycor")
library("polycor")
hetcor(smallData)
######################## FIX VARIABLES #######################
# Delete ones with all NA values
# Numbers: 1,000.00 are read as chars (change to 1000.00?)
smallData$pardavimai_pvm_dekl <- as.numeric(smallData$pardavimai_pvm_dekl)
head(smallData)
str(smallData)
summary(smallData$pardavimai_pvm_dekl)
summary(myData$pardavimai_pvm_dekl)
